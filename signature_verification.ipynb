{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8fb03-0230-49ca-86cf-7272a7bfe721",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b06f0bf-572e-41e5-b10d-9ca1cd71cc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Automatically use GPU if available\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "# Parameters\n",
    "ROOT_DIR = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\misba_model\\signatures\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8ec55-cbf2-489c-97df-031373b1ff84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total writers: 55\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scan_dataset(root_dir):\n",
    "    writers = {}\n",
    "    for writer_folder in sorted(os.listdir(root_dir)):\n",
    "        wpath = os.path.join(root_dir, writer_folder)\n",
    "        if not os.path.isdir(wpath): continue\n",
    "        genuine = glob.glob(os.path.join(wpath, \"original*.png\"))\n",
    "        forged = glob.glob(os.path.join(wpath, \"forgeries*.png\"))\n",
    "        writers[writer_folder] = {\"genuine\": genuine, \"forged\": forged}\n",
    "    return writers\n",
    "\n",
    "writers_dict = scan_dataset(ROOT_DIR)\n",
    "print(\"Total writers:\", len(writers_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baea7b7-d4ef-4cdf-a65f-84f9c87ffcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SignaturePairDataset(Dataset):\n",
    "    def __init__(self, writers_dict, transform=None, num_pairs_per_writer=20):\n",
    "        self.pairs = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for w, files in writers_dict.items():\n",
    "            genuine = files[\"genuine\"]\n",
    "            forged = files[\"forged\"]\n",
    "\n",
    "            # Positive pairs (genuine-genuine)\n",
    "            for _ in range(num_pairs_per_writer):\n",
    "                if len(genuine) >= 2:\n",
    "                    a, b = random.sample(genuine, 2)\n",
    "                    self.pairs.append((a, b, 1))\n",
    "\n",
    "            # Negative pairs (genuine-forged)\n",
    "            for _ in range(num_pairs_per_writer):\n",
    "                if len(genuine) >= 1 and len(forged) >= 1:\n",
    "                    a = random.choice(genuine)\n",
    "                    b = random.choice(forged)\n",
    "                    self.pairs.append((a, b, 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path1, path2, label = self.pairs[idx]\n",
    "        img1 = Image.open(path1).convert(\"L\")\n",
    "        img2 = Image.open(path2).convert(\"L\")\n",
    "\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "\n",
    "        return img1, img2, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e51f483-6b84-43c4-975e-35341a428c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train pairs: 1760 Test pairs: 440\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_writers = list(writers_dict.keys())\n",
    "random.shuffle(all_writers)\n",
    "\n",
    "split = int(0.8 * len(all_writers))\n",
    "train_writers = {w: writers_dict[w] for w in all_writers[:split]}\n",
    "test_writers  = {w: writers_dict[w] for w in all_writers[split:]}\n",
    "\n",
    "train_ds = SignaturePairDataset(train_writers, transform=transform)\n",
    "test_ds  = SignaturePairDataset(test_writers, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(\"Train pairs:\", len(train_ds), \"Test pairs:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e453cf-0c61-426c-864c-e5a5b71d3f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SiameseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(pretrained=True)\n",
    "        base.fc = nn.Linear(base.fc.in_features, 128)  # embedding size 128\n",
    "        self.base = base\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        return self.base(x.repeat(1,3,1,1))  # convert gray->3 channels\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        e1 = self.forward_once(x1)\n",
    "        e2 = self.forward_once(x2)\n",
    "        return e1, e2\n",
    "\n",
    "def contrastive_loss(e1, e2, label, margin=1.0):\n",
    "    dist = F.pairwise_distance(e1, e2)\n",
    "    loss = torch.mean(label * dist**2 + (1-label) * F.relu(margin - dist)**2)\n",
    "    return loss, dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafdd06e-757e-437b-ab0d-cf2640607a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gupta\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\gupta/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:12<00:00, 3.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3201\n",
      "Epoch 2/10, Loss: 0.1517\n",
      "Epoch 3/10, Loss: 0.1043\n",
      "Epoch 4/10, Loss: 0.0724\n",
      "Epoch 5/10, Loss: 0.0508\n",
      "Epoch 6/10, Loss: 0.0385\n",
      "Epoch 7/10, Loss: 0.0324\n",
      "Epoch 8/10, Loss: 0.0229\n",
      "Epoch 9/10, Loss: 0.0187\n",
      "Epoch 10/10, Loss: 0.0175\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SiameseNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img1, img2, label in train_loader:\n",
    "        img1, img2, label = img1.to(DEVICE), img2.to(DEVICE), label.to(DEVICE)\n",
    "\n",
    "        e1, e2 = model(img1, img2)\n",
    "        loss, _ = contrastive_loss(e1, e2, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1021cf24-1e04-4271-9d72-88709e8a3078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "labels, scores = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img1, img2, label in test_loader:\n",
    "        img1, img2 = img1.to(DEVICE), img2.to(DEVICE)\n",
    "        e1, e2 = model(img1, img2)\n",
    "        dist = F.pairwise_distance(e1, e2).cpu().numpy()\n",
    "        scores.extend(dist)\n",
    "        labels.extend(label.numpy())\n",
    "\n",
    "fpr, tpr, thr = roc_curve(labels, -np.array(scores))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\")\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e04a37d-4d63-4dc7-8f28-52b5707a4568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = np.median(scores)\n",
    "preds = [1 if s < threshold else 0 for s in scores]\n",
    "acc = accuracy_score(labels, preds)\n",
    "print(\"Test Accuracy:\", acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8f5069-f203-4254-8ca9-7469514af9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at: C:\\Users\\gupta\\OneDrive\\Desktop\\misba_model\\siamese_signature.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\gupta\\anaconda3\\envs\\tf\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_5672\\2650392372.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Forgery Distance: 3.257835865020752\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Save the trained model ---\n",
    "MODEL_PATH = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\misba_model\\siamese_signature.pth\"\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "print(\"Model saved at:\", MODEL_PATH)\n",
    "\n",
    "# --- Function to load model ---\n",
    "def load_siamese(model_path):\n",
    "    model = SiameseNet().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=DEVICE))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# --- Function to compare two signature images ---\n",
    "def verify_signature(model, img_path1, img_path2, transform, threshold=None):\n",
    "    img1 = Image.open(img_path1).convert(\"L\")\n",
    "    img2 = Image.open(img_path2).convert(\"L\")\n",
    "\n",
    "    img1 = transform(img1).unsqueeze(0).to(DEVICE)\n",
    "    img2 = transform(img2).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        e1, e2 = model(img1, img2)\n",
    "        dist = F.pairwise_distance(e1, e2).item()\n",
    "\n",
    "    if threshold is None:\n",
    "        threshold = 0.5  # default, you can adjust based on ROC/validation\n",
    "\n",
    "    result = \"Genuine\" if dist < threshold else \"Forgery\"\n",
    "    return result, dist\n",
    "\n",
    "# --- Example usage ---\n",
    "model = load_siamese(MODEL_PATH)\n",
    "img1 = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\misba_model\\signatures\\signatures_1\\original_1_1.png\"\n",
    "img2 = r\"C:\\Users\\gupta\\OneDrive\\Desktop\\misba_model\\signatures\\signatures_1\\forgeries_1_1.png\"\n",
    "\n",
    "result, distance = verify_signature(model, img1, img2, transform, threshold=np.median(scores))\n",
    "print(\"Result:\", result, \"Distance:\", distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36734349-a371-47ce-8414-2ed38d350deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
